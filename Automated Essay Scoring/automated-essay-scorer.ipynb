{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AUTOMATED ESSAY SCORER \n------\n*21-09-2021 22:04:00*\n#### **Obective**: \n*To design a system that reads an essay and grades it without any human assistance*\n#### Dataset: \n*Presented by Kaggle*","metadata":{}},{"cell_type":"markdown","source":"## 0. Prepare and Import\n\nThe following phase involves initiating the notebook with the following:\n- Importing necessary pipelines\n- Setting up Constants and pre-trained assets (if any)\n- Importing dataset","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker\n# import all necessary libraries\n\n# For dataframes\nimport pandas as pd \n\n# For numerical arrays\nimport numpy as np \n\n# For stemming/Lemmatisation/POS tagging\nimport spacy\n\n# For getting stopwords\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# For K-Fold cross validation\nfrom sklearn.model_selection import KFold\n\n# For visualizations\nimport matplotlib.pyplot as plt\n\n# For regular expressions\nimport re\n\n# For handling string\nimport string\n\n# For all torch-supported actions\nimport torch\n\n# For spell-check\nfrom spellchecker import SpellChecker\n\n# For performing mathematical operations\nimport math\n\n# For dictionary related activites\nfrom collections import defaultdict\n\n# For counting actions (EDA)\nfrom collections import  Counter\n\n# For count vectorisation (EDA)\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# For one-hot encoding\nfrom tensorflow.keras.utils import to_categorical\n\n# For DL model\nfrom tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\nfrom tensorflow.keras.models import Model, Sequential\n\n# For generating random integers\nfrom random import randint\n\n# For TF-IDF vectorisation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# For padding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# For tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# For plotting\nimport seaborn as sns\n\nprint(\"Necessary libraries imported\")\n\n# Constant variables \n\n# spaCy language lemmatiser model\nsp=spacy.load('en_core_web_sm')\nspell = SpellChecker()\n\nprint(\"Constant variables ready\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-28T13:17:04.566908Z","iopub.execute_input":"2021-09-28T13:17:04.567900Z","iopub.status.idle":"2021-09-28T13:17:26.033631Z","shell.execute_reply.started":"2021-09-28T13:17:04.567272Z","shell.execute_reply":"2021-09-28T13:17:26.032554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"valid=pd.read_csv('../input/asap-aes/valid_set.tsv', sep='\\t', encoding='ISO-8859-1')\ntest=pd.read_csv('../input/asap-aes/test_set.tsv', sep='\\t', encoding='ISO-8859-1')\ndf=pd.read_csv('../input/asap-aes/training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\ndf=df.drop_duplicates(ignore_index=True)\nprint('total rows in train: ',len(df),'\\ntotal rows in valid: ',len(valid),'\\ntotal rows in test: ',len(test))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:26.035580Z","iopub.execute_input":"2021-09-28T13:17:26.035839Z","iopub.status.idle":"2021-09-28T13:17:26.806171Z","shell.execute_reply.started":"2021-09-28T13:17:26.035810Z","shell.execute_reply":"2021-09-28T13:17:26.805255Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1. Exploratory Data Analysis\nThis phase involves complete understanding of what is there in the dataset, and the key nuances that needs to be understood before framing the Input-Output ML pipeline. We perform the following:\n\n- Dataset description (to know what's presented and what's not available)\n","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Dataset Description\nStudying the basic statistics of the dataset, which covers the following aspects:\n- Analysing columns\n- Null-Value statistics\n- Overall column-wise stats\n- Essay prompt types and frequency","metadata":{}},{"cell_type":"code","source":"print('Dataset columns: ')\nprint(df.columns)\nprint('\\nNull Statistics (in %): ')\nprint(df.isnull().sum()* 100 / len(df))\nprint('\\nDataset description: ')\nprint(df.describe())\nprint('\\nEssay prompt frequency: ')\nprint(df.essay_set.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:26.807553Z","iopub.execute_input":"2021-09-28T13:17:26.807800Z","iopub.status.idle":"2021-09-28T13:17:26.893789Z","shell.execute_reply.started":"2021-09-28T13:17:26.807771Z","shell.execute_reply":"2021-09-28T13:17:26.892902Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\n- There are a lot of null values (80 percent plus in most columns). Null Value Treatment is a necessity\n- The prompts are unevenly spread, all the way from 500+ to 1500+\n- There are numerous columns, most of which might not contribute to the performance of training a system\n","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Score Distribution\nHere, we observe the trend of distribution of scores across different essay sets, capturing the different available scores for each domain and for each prompt","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]\n  labels = []\n  sizes = []\n  for x, y in curdf.domain1_score.value_counts().items():\n    labels.append(x)\n    sizes.append(y)\n  ax1 = plt.subplot2grid((3,3),(math.floor((prompt)/3),math.floor((prompt)%3)))\n  plt.pie(sizes,labels=labels,autopct='%1.1f%%')\n  plt.title('Score distribution (Domain 1): Prompt'+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]\nlabels = []\nsizes = []\nfor x, y in curdf.domain2_score.value_counts().items():\n    labels.append(x)\n    sizes.append(y)\nax1 = plt.subplot2grid((3,3),(2,2))\nplt.pie(sizes,labels=labels,autopct='%1.1f%%')\nplt.title('Score distribution (Domain 2): Prompt'+str(prompt+1))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:26.895616Z","iopub.execute_input":"2021-09-28T13:17:26.895867Z","iopub.status.idle":"2021-09-28T13:17:28.807402Z","shell.execute_reply.started":"2021-09-28T13:17:26.895837Z","shell.execute_reply":"2021-09-28T13:17:28.806709Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\nFrom these pie charts, we observe the following:\n- Distribution of scores within an essay set is uneven\n- The range of scores (ie, minimum and maximum attainable mark) for each prompt is highly varying","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Effect of essay-word-lengths over score\nHere, we observe the trend of distribution of scores across different essay sets, capturing the following trends:\n- Total words vs score\n- Word length vs score","metadata":{}},{"cell_type":"code","source":"def get_avg_length(essay):\n    summ=0\n    for word in essay.split():\n        summ+=len(word)\n    return round(summ/len(essay.split()),2)\n\ndf['avg_word_length']=df.essay.apply(lambda x: get_avg_length(x))\nprint(\"Graph for score vs average word length\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24)) # creating a figure with 3 rows and 3 columns of plots\nfig.suptitle('Scores versus average word length')\n\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]  \n  sns.stripplot(ax=axes[prompt%3,math.floor(prompt/3)],\n    data=curdf,\n    x=\"domain1_score\", y=\"avg_word_length\")\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]  \nsns.stripplot(ax=axes[2,2],\n    data=curdf,\n    x=\"domain2_score\", y=\"avg_word_length\")\naxes[2,2].set_title(\"Prompt \"+str(prompt+1))\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:28.808763Z","iopub.execute_input":"2021-09-28T13:17:28.809027Z","iopub.status.idle":"2021-09-28T13:17:32.322478Z","shell.execute_reply.started":"2021-09-28T13:17:28.808992Z","shell.execute_reply":"2021-09-28T13:17:32.321454Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"Graph for score vs total words\")\n\n\ndf['total_words']=df.essay.apply(lambda x: len(x.split()))\nfig, axes = plt.subplots(3, 3, figsize=(24,24)) # creating a figure with 3 rows and 3 columns of plots\nfig.suptitle('Scores versus total words')\n\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]  \n  sns.boxplot(ax=axes[prompt%3,math.floor(prompt/3)],\n    data=curdf,\n    x=\"domain1_score\", y=\"total_words\")\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]  \nsns.boxplot(ax=axes[2,2],\n    data=curdf,\n    x=\"domain2_score\", y=\"total_words\")\naxes[2,2].set_title(\"Prompt \"+str(prompt+1))\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:32.324068Z","iopub.execute_input":"2021-09-28T13:17:32.324391Z","iopub.status.idle":"2021-09-28T13:17:36.020629Z","shell.execute_reply.started":"2021-09-28T13:17:32.324336Z","shell.execute_reply":"2021-09-28T13:17:36.019512Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two seaborn-figures:\n- Average-word-length is tightly packed, densley populated around the 3-5 region for almost all prompts, with a few out-of-range-outliers\n- The box-range of total words used in an essay moves up the graph with increase in domain's score, pin-pointing a trend of length versus score, with the presence of few outliers","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Unigram analysis\nThe primary goal here is to see what words are most frequently used. This will be done in the following ways:\n- Frequency of stop-words used\n- Most commonly occuring non-stop-words in each essay set","metadata":{}},{"cell_type":"code","source":"print(\"Stop-word freuency\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24))\nfig.suptitle('Stop-word freuency')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  curdf=df[df['essay_set']==prompt+1]  \n  counter=Counter((\" \".join(curdf.essay)).split())\n  most=counter.most_common()\n  x=[]\n  y=[]\n  for word,count in most[:10]:\n      if (word in STOP_WORDS) :\n          x.append(word)\n          y.append(count)\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[2,2].set_title(\"NaN\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:36.022679Z","iopub.execute_input":"2021-09-28T13:17:36.023035Z","iopub.status.idle":"2021-09-28T13:17:38.682586Z","shell.execute_reply.started":"2021-09-28T13:17:36.022991Z","shell.execute_reply":"2021-09-28T13:17:38.681564Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"Most commonly occcuring words in all essay prompts\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24))\nfig.suptitle('Common-word frequency')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  curdf=df[df['essay_set']==prompt+1]  \n  counter=Counter((\" \".join(curdf.essay)).split())\n  most=counter.most_common()\n  x=[]\n  y=[]\n  for word,count in most[:50]:\n      if (word.lower() not in STOP_WORDS):\n          x.append(word)\n          y.append(count)\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[2,2].set_title(\"NaN\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:38.684060Z","iopub.execute_input":"2021-09-28T13:17:38.684298Z","iopub.status.idle":"2021-09-28T13:17:41.863730Z","shell.execute_reply.started":"2021-09-28T13:17:38.684270Z","shell.execute_reply":"2021-09-28T13:17:41.863044Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two series of barcharts:\n- The frequency of stop-words in each word is heavy enough, raising the need to do stopword-removal during data cleaning and feature-formatting\n- The most commonly words are in direct relationship with the prompt/essay_set chosen. The most commonly occuring words are in extremely high correlation with the essay set's question","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Bigram analysis\nThe primary goal here is to analyse the trend of bigrams used in each essay","metadata":{"execution":{"iopub.status.busy":"2021-09-27T15:18:01.599715Z","iopub.execute_input":"2021-09-27T15:18:01.600518Z","iopub.status.idle":"2021-09-27T15:18:01.607539Z","shell.execute_reply.started":"2021-09-27T15:18:01.600467Z","shell.execute_reply":"2021-09-27T15:18:01.606599Z"}}},{"cell_type":"code","source":"def get_top_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\nprint(\"Bigram analysis\")\n\nfig, axes = plt.subplots(3,3, figsize=(12,12))\nfig.suptitle('Bigram analysis')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  top_bigrams=get_top_bigrams(df[df['essay_set']==prompt+1].essay)[:10]\n  x,y=map(list,zip(*top_bigrams))\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:17:41.864864Z","iopub.execute_input":"2021-09-28T13:17:41.865213Z","iopub.status.idle":"2021-09-28T13:17:57.768958Z","shell.execute_reply.started":"2021-09-28T13:17:41.865186Z","shell.execute_reply":"2021-09-28T13:17:57.767929Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two series of barcharts:\n- The frequency of stop-words in each word is heavy enough, raising the need to do stopword-removal during data cleaning and feature-formatting\n- The most commonly words are in direct relationship with the prompt/essay_set chosen. The most commonly occuring words are in extremely high correlation with the essay set's question","metadata":{}},{"cell_type":"markdown","source":"## 2. DATA CLEANING\nAs observed with the results of EDA, the following are done for each essay in each prompt:\n- Removing punctuations and numbers\n- Spell-checking\n- Removing stop-words\n- Lemmatization","metadata":{}},{"cell_type":"code","source":"print(df.head())\npunctuation_counter=0\ndigit_counter=0\n\ndef remove_punct(text):\n    global punctuation_counter\n    for i in string.punctuation:\n      punctuation_counter+=text.count(i)\n    \n    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n    text=text.translate(translator)\n    return re.sub(' +', ' ', text)\n\n\ndef remove_digits(text):\n    global digit_counter\n    for c in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]:\n        digit_counter+=text.count(c)\n\n    text = re.sub(r'[0-9]', ' ', text)\n    return re.sub(' +', ' ', text)\n\n\ndef lemmatize(text):\n     return \" \".join(map(lambda x : x.lemma_, sp(text)))\n\n\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n\ndef stopwords(text):\n  return \" \".join(map(lambda x : x.lemma_,\n                      [token for token in sp(text) if not token.is_stop]))\ndef cleaner(text):\n    text=text.lower()\n    text=remove_punct(text)\n    text=remove_digits(text)\n    text=correct_spellings(text) #time-intensive\n    text=stopwords(text)\n    text=lemmatize(text)\n    return text.rstrip()\n\ndf['corpus']=df['essay'].apply(lambda x: cleaner(x))\nprint(digit_counter,' digits removed, \\n',punctuation_counter,' punctuations removed')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T19:10:07.783132Z","iopub.execute_input":"2021-09-28T19:10:07.783447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('hi')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:24:46.969092Z","iopub.execute_input":"2021-09-28T15:24:46.969988Z","iopub.status.idle":"2021-09-28T15:24:46.977221Z","shell.execute_reply.started":"2021-09-28T15:24:46.969919Z","shell.execute_reply":"2021-09-28T15:24:46.975832Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## STEP THREE","metadata":{}},{"cell_type":"code","source":"dataset=[]\nidx=0\nMAX_SEQUENCE_LENGTH=500\n\nfor i in range(0,8):\n  dataset.append(df[df.essay_set==i+1].rename(columns={\"domain1_score\":\"score\"}).loc[:,[\"corpus\",\"score\"]])\ndataset.append(df[df.essay_set==2].rename(columns={\"domain2_score\":\"score\"}).loc[:,[\"corpus\",\"score\"]])\n# Create tokenizers (objects that convert text to vectors) and sequence vectors\n# For each prompt separately\n\ntokenizer = []\nsequences=[]\nlabels=[]\nfor prompt in range(0,9):\n  tokenizer_curr=Tokenizer() \n  tokenizer_curr.fit_on_texts(dataset[prompt].corpus) \n  sequence_curr=tokenizer_curr.texts_to_sequences(dataset[prompt].corpus)\n  word_index = tokenizer_curr.word_index   \n  print('Found ',len(word_index),' unique tokens for prompt ' ,prompt, ' With ',len(sequence_curr),' essays, and the maximum string length being ',max([len(i) for i in sequence_curr]))\n  sequence_curr = pad_sequences(sequence_curr, maxlen=MAX_SEQUENCE_LENGTH)\n  \n  tokenizer.append(tokenizer_curr)\n  sequences.append(sequence_curr)\n  labels.append(np.asarray(dataset[prompt].score))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T19:09:57.850570Z","iopub.execute_input":"2021-09-28T19:09:57.851736Z","iopub.status.idle":"2021-09-28T19:10:00.460881Z","shell.execute_reply.started":"2021-09-28T19:09:57.851684Z","shell.execute_reply":"2021-09-28T19:10:00.459782Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## STEP FOUR","metadata":{}},{"cell_type":"code","source":"model=[]\nhistory=[]\nMAX_NUM_WORDS=10000 \nEMBEDDING_DIM=100\nfor prompt in range(0,9):\n  rnnmodel = Sequential()\n  rnnmodel.add(Embedding(MAX_NUM_WORDS, EMBEDDING_DIM))\n  rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n  rnnmodel.add(Dense(32, activation='relu'))\n  rnnmodel.add(Dense(1, activation='relu'))\n  rnnmodel.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['mae'])\n  print(rnnmodel.summary())\n  fold=0\n  for train_index, test_index in KFold(3,shuffle=True).split(sequences[prompt]):\n    print('\\n Prompt ',prompt+1,' Fold ',fold+1)\n    x_train, x_val = sequences[prompt][train_index], sequences[prompt][test_index]\n    y_train, y_val = labels[prompt][train_index], labels[prompt][test_index]\n    his=rnnmodel.fit(x_train, y_train,\n            batch_size=32,\n            epochs=10,\n            validation_data=(x_val, y_val))\n    \n    #path = \"/content/gdrive/My Drive/aes_born_\"+str(prompt)+\".h5\" \n    #rnnmodel.save(path)\n\n    plt.plot(his.history['loss'])\n    plt.plot(his.history['val_loss'])\n    plt.title('PROMPT '+str(prompt)+' fold '+str(fold))\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n  \n    history.append(his)\n    fold+=1\n\n    # summarize history for loss\n\n  model.append(rnnmodel)\n\nprint('all done')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:29:46.865743Z","iopub.execute_input":"2021-09-28T15:29:46.866112Z","iopub.status.idle":"2021-09-28T17:51:39.441511Z","shell.execute_reply.started":"2021-09-28T15:29:46.866079Z","shell.execute_reply":"2021-09-28T17:51:39.440151Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## STEP FIVE: SUBMIT","metadata":{}},{"cell_type":"code","source":"%%time\ntest=pd.read_csv('../input/asap-aes/test_set.tsv', sep='\\t', encoding='ISO-8859-1')\n\nprint(test.head())\ntest['corpus']=test.essay.apply(lambda x: cleaner(x))\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:35:47.482895Z","iopub.execute_input":"2021-09-28T18:35:47.483241Z","iopub.status.idle":"2021-09-28T18:55:56.576832Z","shell.execute_reply.started":"2021-09-28T18:35:47.483209Z","shell.execute_reply":"2021-09-28T18:55:56.575747Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"dataset=[]\nidx=0\nMAX_SEQUENCE_LENGTH=500\n\nfor i in range(0,8):\n  dataset.append(test[test.essay_set==i+1].rename(columns={\"domain1_predictionid\":\"id\"}).loc[:,[\"id\",\"corpus\"]])\ndataset.append(test[test.essay_set==2].rename(columns={\"domain2_predictionid\":\"id\"}).loc[:,[\"id\",\"corpus\"]])\n# Create tokenizers (objects that convert text to vectors) and sequence vectors\n# For each prompt separately\n\nsequences=[]\nanswers=[]\nfor prompt in range(0,9):\n  sequence_curr=tokenizer[prompt].texts_to_sequences(dataset[prompt].corpus)\n  sequence_curr = pad_sequences(sequence_curr, maxlen=MAX_SEQUENCE_LENGTH)\n  answer=model[prompt].predict(sequence_curr)\n  answers.append(answer)\n  dataset[prompt]['score'] = answer.tolist()\n  dataset[prompt]['score'] = dataset[prompt]['score'].apply(lambda x: round(x[0],0))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T19:02:52.716286Z","iopub.execute_input":"2021-09-28T19:02:52.717299Z","iopub.status.idle":"2021-09-28T19:03:08.947231Z","shell.execute_reply.started":"2021-09-28T19:02:52.717244Z","shell.execute_reply":"2021-09-28T19:03:08.946161Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"my_submission=pd.concat(dataset)\nmy_submission=my_submission[[\"id\",\"score\"]]\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T19:04:10.563116Z","iopub.execute_input":"2021-09-28T19:04:10.563451Z","iopub.status.idle":"2021-09-28T19:04:10.595513Z","shell.execute_reply.started":"2021-09-28T19:04:10.563419Z","shell.execute_reply":"2021-09-28T19:04:10.594428Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"my_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T19:04:14.710098Z","iopub.execute_input":"2021-09-28T19:04:14.710480Z","iopub.status.idle":"2021-09-28T19:04:14.723545Z","shell.execute_reply.started":"2021-09-28T19:04:14.710446Z","shell.execute_reply":"2021-09-28T19:04:14.722508Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}