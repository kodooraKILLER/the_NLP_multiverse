{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AUTOMATED ESSAY SCORER \n------\n*21-09-2021 22:04:00*\n#### **Obective**: \n*To design a system that reads an essay and grades it without any human assistance*\n#### Dataset: \n*Presented by Kaggle*","metadata":{}},{"cell_type":"markdown","source":"## 0. Prepare and Import\n\nThe following phase involves initiating the notebook with the following:\n- Importing necessary pipelines\n- Setting up Constants and pre-trained assets (if any)\n- Importing dataset","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker\n# import all necessary libraries\n\n# For dataframes\nimport pandas as pd \n\n# For numerical arrays\nimport numpy as np \n\n# For stemming/Lemmatisation/POS tagging\nimport spacy\n\n# For getting stopwords\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# For K-Fold cross validation\nfrom sklearn.model_selection import KFold\n\n# For visualizations\nimport matplotlib.pyplot as plt\n\n# For regular expressions\nimport re\n\n# For handling string\nimport string\n\n# For all torch-supported actions\nimport torch\n\n# For spell-check\nfrom spellchecker import SpellChecker\n\n# For performing mathematical operations\nimport math\n\n# For dictionary related activites\nfrom collections import defaultdict\n\n# For counting actions (EDA)\nfrom collections import  Counter\n\n# For count vectorisation (EDA)\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# For one-hot encoding\nfrom tensorflow.keras.utils import to_categorical\n\n# For DL model\nfrom tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\nfrom tensorflow.keras.models import Model, Sequential\n\n# For generating random integers\nfrom random import randint\n\n# For TF-IDF vectorisation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# For padding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# For tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# For plotting\nimport seaborn as sns\n\nprint(\"Necessary libraries imported\")\n\n# Constant variables \n\n# spaCy language lemmatiser model\nsp=spacy.load('en_core_web_sm')\nspell = SpellChecker()\n\nprint(\"Constant variables ready\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T16:34:08.845805Z","iopub.execute_input":"2021-09-27T16:34:08.846068Z","iopub.status.idle":"2021-09-27T16:34:26.103131Z","shell.execute_reply.started":"2021-09-27T16:34:08.846042Z","shell.execute_reply":"2021-09-27T16:34:26.102132Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"valid=pd.read_csv('../input/asap-aes/valid_set.tsv', sep='\\t', encoding='ISO-8859-1')\ntest=pd.read_csv('../input/asap-aes/test_set.tsv', sep='\\t', encoding='ISO-8859-1')\ndf=pd.read_csv('../input/asap-aes/training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\ndf=df.drop_duplicates(ignore_index=True)\nprint('total rows in train: ',len(df),'\\ntotal rows in valid: ',len(valid),'\\ntotal rows in test: ',len(test))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:26.105007Z","iopub.execute_input":"2021-09-27T16:34:26.105344Z","iopub.status.idle":"2021-09-27T16:34:26.785726Z","shell.execute_reply.started":"2021-09-27T16:34:26.105300Z","shell.execute_reply":"2021-09-27T16:34:26.784737Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Exploratory Data Analysis\nThis phase involves complete understanding of what is there in the dataset, and the key nuances that needs to be understood before framing the Input-Output ML pipeline. We perform the following:\n\n- Dataset description (to know what's presented and what's not available)\n","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Dataset Description\nStudying the basic statistics of the dataset, which covers the following aspects:\n- Analysing columns\n- Null-Value statistics\n- Overall column-wise stats\n- Essay prompt types and frequency","metadata":{}},{"cell_type":"code","source":"print('Dataset columns: ')\nprint(df.columns)\nprint('\\nNull Statistics (in %): ')\nprint(df.isnull().sum()* 100 / len(df))\nprint('\\nDataset description: ')\nprint(df.describe())\nprint('\\nEssay prompt frequency: ')\nprint(df.essay_set.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:26.787092Z","iopub.execute_input":"2021-09-27T16:34:26.787340Z","iopub.status.idle":"2021-09-27T16:34:26.866815Z","shell.execute_reply.started":"2021-09-27T16:34:26.787306Z","shell.execute_reply":"2021-09-27T16:34:26.865964Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\n- There are a lot of null values (80 percent plus in most columns). Null Value Treatment is a necessity\n- The prompts are unevenly spread, all the way from 500+ to 1500+\n- There are numerous columns, most of which might not contribute to the performance of training a system\n","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Score Distribution\nHere, we observe the trend of distribution of scores across different essay sets, capturing the different available scores for each domain and for each prompt","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]\n  labels = []\n  sizes = []\n  for x, y in curdf.domain1_score.value_counts().items():\n    labels.append(x)\n    sizes.append(y)\n  ax1 = plt.subplot2grid((3,3),(math.floor((prompt)/3),math.floor((prompt)%3)))\n  plt.pie(sizes,labels=labels,autopct='%1.1f%%')\n  plt.title('Score distribution (Domain 1): Prompt'+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]\nlabels = []\nsizes = []\nfor x, y in curdf.domain2_score.value_counts().items():\n    labels.append(x)\n    sizes.append(y)\nax1 = plt.subplot2grid((3,3),(2,2))\nplt.pie(sizes,labels=labels,autopct='%1.1f%%')\nplt.title('Score distribution (Domain 2): Prompt'+str(prompt+1))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:26.868380Z","iopub.execute_input":"2021-09-27T16:34:26.868606Z","iopub.status.idle":"2021-09-27T16:34:28.576786Z","shell.execute_reply.started":"2021-09-27T16:34:26.868579Z","shell.execute_reply":"2021-09-27T16:34:28.576204Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\nFrom these pie charts, we observe the following:\n- Distribution of scores within an essay set is uneven\n- The range of scores (ie, minimum and maximum attainable mark) for each prompt is highly varying","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Effect of essay-word-lengths over score\nHere, we observe the trend of distribution of scores across different essay sets, capturing the following trends:\n- Total words vs score\n- Word length vs score","metadata":{}},{"cell_type":"code","source":"def get_avg_length(essay):\n    summ=0\n    for word in essay.split():\n        summ+=len(word)\n    return round(summ/len(essay.split()),2)\n\ndf['avg_word_length']=df.essay.apply(lambda x: get_avg_length(x))\nprint(\"Graph for score vs average word length\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24)) # creating a figure with 3 rows and 3 columns of plots\nfig.suptitle('Scores versus average word length')\n\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]  \n  sns.stripplot(ax=axes[prompt%3,math.floor(prompt/3)],\n    data=curdf,\n    x=\"domain1_score\", y=\"avg_word_length\")\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]  \nsns.stripplot(ax=axes[2,2],\n    data=curdf,\n    x=\"domain2_score\", y=\"avg_word_length\")\naxes[2,2].set_title(\"Prompt \"+str(prompt+1))\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:28.577753Z","iopub.execute_input":"2021-09-27T16:34:28.578379Z","iopub.status.idle":"2021-09-27T16:34:31.515987Z","shell.execute_reply.started":"2021-09-27T16:34:28.578346Z","shell.execute_reply":"2021-09-27T16:34:31.515135Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"Graph for score vs total words\")\n\n\ndf['total_words']=df.essay.apply(lambda x: len(x.split()))\nfig, axes = plt.subplots(3, 3, figsize=(24,24)) # creating a figure with 3 rows and 3 columns of plots\nfig.suptitle('Scores versus total words')\n\nfor prompt in range(0,8):\n  curdf=df[df['essay_set']==prompt+1]  \n  sns.boxplot(ax=axes[prompt%3,math.floor(prompt/3)],\n    data=curdf,\n    x=\"domain1_score\", y=\"total_words\")\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\nprompt=1\ncurdf=df[df['essay_set']==prompt+1]  \nsns.boxplot(ax=axes[2,2],\n    data=curdf,\n    x=\"domain2_score\", y=\"total_words\")\naxes[2,2].set_title(\"Prompt \"+str(prompt+1))\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:31.517350Z","iopub.execute_input":"2021-09-27T16:34:31.518039Z","iopub.status.idle":"2021-09-27T16:34:34.674994Z","shell.execute_reply.started":"2021-09-27T16:34:31.517994Z","shell.execute_reply":"2021-09-27T16:34:34.673955Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two seaborn-figures:\n- Average-word-length is tightly packed, densley populated around the 3-5 region for almost all prompts, with a few out-of-range-outliers\n- The box-range of total words used in an essay moves up the graph with increase in domain's score, pin-pointing a trend of length versus score, with the presence of few outliers","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Unigram analysis\nThe primary goal here is to see what words are most frequently used. This will be done in the following ways:\n- Frequency of stop-words used\n- Most commonly occuring non-stop-words in each essay set","metadata":{}},{"cell_type":"code","source":"print(\"Stop-word freuency\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24))\nfig.suptitle('Stop-word freuency')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  curdf=df[df['essay_set']==prompt+1]  \n  counter=Counter((\" \".join(curdf.essay)).split())\n  most=counter.most_common()\n  x=[]\n  y=[]\n  for word,count in most[:10]:\n      if (word in STOP_WORDS) :\n          x.append(word)\n          y.append(count)\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[2,2].set_title(\"NaN\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:34.676272Z","iopub.execute_input":"2021-09-27T16:34:34.676511Z","iopub.status.idle":"2021-09-27T16:34:36.920506Z","shell.execute_reply.started":"2021-09-27T16:34:34.676485Z","shell.execute_reply":"2021-09-27T16:34:36.919954Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"Most commonly occcuring words in all essay prompts\")\n\nfig, axes = plt.subplots(3, 3, figsize=(24,24))\nfig.suptitle('Common-word frequency')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  curdf=df[df['essay_set']==prompt+1]  \n  counter=Counter((\" \".join(curdf.essay)).split())\n  most=counter.most_common()\n  x=[]\n  y=[]\n  for word,count in most[:50]:\n      if (word.lower() not in STOP_WORDS):\n          x.append(word)\n          y.append(count)\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[2,2].set_title(\"NaN\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:34:36.921529Z","iopub.execute_input":"2021-09-27T16:34:36.921832Z","iopub.status.idle":"2021-09-27T16:34:39.572025Z","shell.execute_reply.started":"2021-09-27T16:34:36.921808Z","shell.execute_reply":"2021-09-27T16:34:39.571453Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two series of barcharts:\n- The frequency of stop-words in each word is heavy enough, raising the need to do stopword-removal during data cleaning and feature-formatting\n- The most commonly words are in direct relationship with the prompt/essay_set chosen. The most commonly occuring words are in extremely high correlation with the essay set's question","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Bigram analysis\nThe primary goal here is to analyse the trend of bigrams used in each essay","metadata":{"execution":{"iopub.status.busy":"2021-09-27T15:18:01.599715Z","iopub.execute_input":"2021-09-27T15:18:01.600518Z","iopub.status.idle":"2021-09-27T15:18:01.607539Z","shell.execute_reply.started":"2021-09-27T15:18:01.600467Z","shell.execute_reply":"2021-09-27T15:18:01.606599Z"}}},{"cell_type":"code","source":"def get_top_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\nprint(\"Bigram analysis\")\n\nfig, axes = plt.subplots(3,3, figsize=(12,12))\nfig.suptitle('Bigram analysis')\n\nfor prompt in range(0,8):\n  dct=defaultdict(int) \n  top_bigrams=get_top_bigrams(df[df['essay_set']==prompt+1].essay)[:10]\n  x,y=map(list,zip(*top_bigrams))\n  sns.barplot(ax=axes[prompt%3,math.floor(prompt/3)],x=y,y=x)\n  axes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\n\naxes[prompt%3,math.floor(prompt/3)].set_title(\"Prompt \"+str(prompt+1))\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T16:35:08.936425Z","iopub.execute_input":"2021-09-27T16:35:08.936891Z","iopub.status.idle":"2021-09-27T16:35:20.161181Z","shell.execute_reply.started":"2021-09-27T16:35:08.936858Z","shell.execute_reply":"2021-09-27T16:35:20.160552Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n\nWe get the following information from these two series of barcharts:\n- We need to treat stop-words before creating any model that involves restoring the sequence-ness of the words\n- Most frequently occuring bigrams have something to do against the scoring of each prompt","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}}]}